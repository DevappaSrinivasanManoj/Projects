{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#EPUB\n",
        "import requests\n",
        "from lxml import html\n",
        "import os\n",
        "\n",
        "# URL of the LibGen book page\n",
        "url = \"https://libgen.li/ads.php?md5=164cd9a525c2829f5489439e9d60721b\"\n",
        "\n",
        "# Send a GET request to fetch the page content\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Ensure request was successful\n",
        "\n",
        "# Parse the HTML content using lxml\n",
        "tree = html.fromstring(response.content)\n",
        "\n",
        "# Find the <a> tag that contains <h2>GET</h2> using XPath\n",
        "get_link_element = tree.xpath(\"//a[h2[normalize-space()='GET']]\")\n",
        "\n",
        "if get_link_element:\n",
        "    # Extract the href attribute (relative download link)\n",
        "    relative_link = get_link_element[0].attrib.get(\"href\", \"\")\n",
        "\n",
        "    # Convert to absolute URL\n",
        "    download_url = f\"https://libgen.li/{relative_link.lstrip('/')}\"  # Ensure no double slashes\n",
        "\n",
        "    print(\"Download link found:\", download_url)\n",
        "\n",
        "    # Send a GET request to download the file\n",
        "    file_response = requests.get(download_url, stream=True)\n",
        "    file_response.raise_for_status()\n",
        "\n",
        "    # Extract file name from headers if available\n",
        "    content_disposition = file_response.headers.get(\"Content-Disposition\")\n",
        "    if content_disposition and \"filename=\" in content_disposition:\n",
        "        file_name = content_disposition.split(\"filename=\")[-1].strip().strip('\"')\n",
        "    else:\n",
        "        # Fallback: Extract filename from the URL\n",
        "        file_name = os.path.basename(download_url.split(\"?\")[0])\n",
        "\n",
        "    # Ensure the file has an .epub extension\n",
        "    if not file_name.endswith(\".epub\"):\n",
        "        file_name += \".epub\"\n",
        "\n",
        "    # Save the EPUB file\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        for chunk in file_response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "\n",
        "    print(f\"EPUB file downloaded successfully as {file_name}\")\n",
        "\n",
        "else:\n",
        "    print(\"GET button not found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW8XQhmxQMED",
        "outputId": "0fba4680-a331-476e-9efc-287821f2b61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download link found: https://libgen.li/get.php?md5=164cd9a525c2829f5489439e9d60721b&key=2XC3ZJ92DZYILEUU\n",
            "EPUB file downloaded successfully as [Genghis 3 ] Iggulden, Conn - Bones of the Hills (2010, HarperCollins Publishers Limited) - libgen.li.epub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PDF\n",
        "import requests\n",
        "from lxml import html\n",
        "import os\n",
        "\n",
        "# URL of the LibGen book page\n",
        "url = \"http://libgen.li/ads.php?md5=ed372ab968c3d988e0490962553aa3cf\"\n",
        "\n",
        "# Send a GET request to fetch the page content\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Ensure request was successful\n",
        "\n",
        "# Parse the HTML content using lxml\n",
        "tree = html.fromstring(response.content)\n",
        "\n",
        "# Find the <a> tag that contains <h2>GET</h2> using XPath\n",
        "get_link_element = tree.xpath(\"//a[h2[normalize-space()='GET']]\")\n",
        "\n",
        "if get_link_element:\n",
        "    # Extract the href attribute (relative download link)\n",
        "    relative_link = get_link_element[0].attrib.get(\"href\", \"\")\n",
        "\n",
        "    # Convert to absolute URL\n",
        "    download_url = f\"https://libgen.li/{relative_link.lstrip('/')}\"  # Ensure no double slashes\n",
        "\n",
        "    print(\"Download link found:\", download_url)\n",
        "\n",
        "    # Send a GET request to download the file\n",
        "    file_response = requests.get(download_url, stream=True)\n",
        "    file_response.raise_for_status()\n",
        "\n",
        "    # Extract file name from headers if available\n",
        "    content_disposition = file_response.headers.get(\"Content-Disposition\")\n",
        "    if content_disposition and \"filename=\" in content_disposition:\n",
        "        file_name = content_disposition.split(\"filename=\")[-1].strip().strip('\"')\n",
        "    else:\n",
        "        # Fallback: Extract filename from the URL\n",
        "        file_name = os.path.basename(download_url.split(\"?\")[0])\n",
        "\n",
        "    # Ensure the file has an .epub extension\n",
        "    if not file_name.endswith(\".pdf\"):\n",
        "        file_name += \".pdf\"\n",
        "\n",
        "    # Save the EPUB file\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        for chunk in file_response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "\n",
        "    print(f\"PDF file downloaded successfully as {file_name}\")\n",
        "\n",
        "else:\n",
        "    print(\"GET button not found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr0bsf_Ee5y3",
        "outputId": "45d1502d-7503-46e6-d96f-dc0d9855c469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download link found: https://libgen.li/get.php?md5=ed372ab968c3d988e0490962553aa3cf&key=0SV3ILPSGLXH4XQE\n",
            "PDF file downloaded successfully as  Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, Cliffo - Introduction to Algorithms (2009) - libgen.li.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ebooklib beautifulsoup4 bleach"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysmmp19wcPg7",
        "outputId": "c65ade47-1de4-41ca-9de4-0c14f0f93bf8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ebooklib in /usr/local/lib/python3.11/dist-packages (0.19)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from ebooklib) (5.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from ebooklib) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ebooklib import epub, ITEM_DOCUMENT, ITEM_IMAGE, ITEM_STYLE\n",
        "from bs4 import BeautifulSoup\n",
        "import bleach\n",
        "\n",
        "SAFE_TAGS = [\n",
        "    'html', 'head', 'body', 'title',\n",
        "    'p', 'br', 'b', 'i', 'strong', 'em',\n",
        "    'ul', 'ol', 'li', 'blockquote',\n",
        "    'h1', 'h2', 'h3', 'h4', 'h5', 'h6',\n",
        "    'code', 'pre', 'hr'\n",
        "]\n",
        "\n",
        "SAFE_ATTRS = {}\n",
        "\n",
        "def sanitize_html(html_content):\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "    cleaned_html = bleach.clean(\n",
        "        str(soup),\n",
        "        tags=SAFE_TAGS,\n",
        "        attributes=SAFE_ATTRS,\n",
        "        strip=True\n",
        "    )\n",
        "    return cleaned_html\n",
        "\n",
        "def sanitize_epub(input_path):\n",
        "    base, ext = os.path.splitext(input_path)\n",
        "    output_path = f\"{base}_sanitized{ext}\"\n",
        "\n",
        "    book = epub.read_epub(input_path)\n",
        "    new_book = epub.EpubBook()\n",
        "\n",
        "    # Copy metadata (safe fallback with .get)\n",
        "    id_ = book.get_metadata('DC', 'identifier')\n",
        "    title = book.get_metadata('DC', 'title')\n",
        "    lang = book.get_metadata('DC', 'language')\n",
        "\n",
        "    if id_: new_book.set_identifier(id_[0][0])\n",
        "    if title: new_book.set_title(title[0][0])\n",
        "    if lang: new_book.set_language(lang[0][0])\n",
        "\n",
        "    for item in book.get_items():\n",
        "        if item.get_type() == ITEM_DOCUMENT:\n",
        "            cleaned_html = sanitize_html(item.get_content().decode('utf-8'))\n",
        "            item.set_content(cleaned_html.encode('utf-8'))\n",
        "            new_book.add_item(item)\n",
        "        elif item.get_type() == ITEM_IMAGE:\n",
        "            new_book.add_item(item)\n",
        "        elif item.get_type() == ITEM_STYLE:\n",
        "            continue\n",
        "        else:\n",
        "            new_book.add_item(item)\n",
        "\n",
        "    new_book.spine = book.spine or ['nav']\n",
        "    new_book.toc = book.toc or []\n",
        "\n",
        "    epub.write_epub(output_path, new_book)\n",
        "    print(f\"Sanitized EPUB saved to: {output_path}\")\n",
        "\n",
        "# === Example usage ===\n",
        "if __name__ == \"__main__\":\n",
        "    sanitize_epub(\"Your_money_or_your_life.epub\")  # Replace with your filename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cliprWMEcXHC",
        "outputId": "fa6a75ab-532b-4763-c30e-a8db510a0bea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanitized EPUB saved to: Your_money_or_your_life_sanitized.epub\n"
          ]
        }
      ]
    }
  ]
}